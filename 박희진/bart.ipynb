{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Und die Könige der Erde, die Vergewaltigung begangen haben und mit ihr lebhaft gelebt haben, werden über sie weinen und für sie weinen, wenn sie den Rauch ihres Brandes sehen,']\n"
     ]
    }
   ],
   "source": [
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
    "\n",
    "article_en = \" And the kings of the earth, who have committed fornication and lived deliciously with her, shall bewail her, and lament for her, when they shall see the smoke of her burning,\"\n",
    "\n",
    "model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
    "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
    "\n",
    "# translate English to German\n",
    "tokenizer.src_lang = \"en_XX\"\n",
    "encoded_en = tokenizer(article_en, return_tensors=\"pt\")\n",
    "generated_tokens = model.generate(\n",
    "    **encoded_en,\n",
    "    forced_bos_token_id=tokenizer.lang_code_to_id[\"de_DE\"]\n",
    ")\n",
    "translated_text = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "print(translated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 테이블의 데이터수는 총 31102개 입니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kdp\\AppData\\Local\\Temp\\ipykernel_18988\\3303228363.py:19: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  endeDF = pd.read_sql(sql, conn)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>de</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the beginning God created the heaven and th...</td>\n",
       "      <td>Am Anfang schuf Gott Himmel und Erde.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>And the earth was without form, and void; and ...</td>\n",
       "      <td>Und die Erde war wüst und leer, und es war fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>And God said, Let there be light: and there wa...</td>\n",
       "      <td>Und Gott sprach: Es werde Licht! und es ward L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>And God saw the light, that it was good: and G...</td>\n",
       "      <td>Und Gott sah, daß das Licht gut war. Da schied...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>And God called the light Day, and the darkness...</td>\n",
       "      <td>und nannte das Licht Tag und die Finsternis Na...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  en  \\\n",
       "0  In the beginning God created the heaven and th...   \n",
       "1  And the earth was without form, and void; and ...   \n",
       "2  And God said, Let there be light: and there wa...   \n",
       "3  And God saw the light, that it was good: and G...   \n",
       "4  And God called the light Day, and the darkness...   \n",
       "\n",
       "                                                  de  \n",
       "0              Am Anfang schuf Gott Himmel und Erde.  \n",
       "1  Und die Erde war wüst und leer, und es war fin...  \n",
       "2  Und Gott sprach: Es werde Licht! und es ward L...  \n",
       "3  Und Gott sah, daß das Licht gut war. Da schied...  \n",
       "4  und nannte das Licht Tag und die Finsternis Na...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "\n",
    "# 데이터 베이스 연결하기\n",
    "conn = pymysql.connect(host='1.251.203.204',\n",
    "                       user='root',\n",
    "                       password='kdt5',\n",
    "                       db='Team4',\n",
    "                       charset='utf8',\n",
    "                       port=33065)\n",
    "\n",
    "curs = conn.cursor()\n",
    "\n",
    "# 검색 명령어 사용 \n",
    "sql = \"SELECT en.text as en, de.text as de FROM language_en en join language_de de on en.id = de.id;\"\n",
    "curs.execute(sql)\n",
    "result = curs.fetchall()\n",
    "print(\"현재 테이블의 데이터수는 총 {}개 입니다.\".format(len(result)))\n",
    "endeDF = pd.read_sql(sql, conn)\n",
    "\n",
    "# 데이터베이스 연결 종료\n",
    "conn.close()\n",
    "endeDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_texts = endeDF[\"en\"].tolist()\n",
    "target_texts = endeDF[\"de\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/1944 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 데이터셋 클래스 정의\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, source_texts, target_texts, tokenizer, max_length=512):\n",
    "        self.source_texts = source_texts\n",
    "        self.target_texts = target_texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.source_texts)\n",
    "    def __getitem__(self, idx):\n",
    "        source_text = self.source_texts[idx]\n",
    "        target_text = self.target_texts[idx]\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            source_text,\n",
    "            target_text,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        target_encoding = self.tokenizer(\n",
    "            target_text,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        encoding[\"labels\"] = target_encoding[\"input_ids\"]\n",
    "        \n",
    "        return encoding\n",
    "\n",
    "\n",
    "\n",
    "# 파인튜닝에 사용할 데이터 준비\n",
    "source_texts = endeDF[\"en\"].tolist()\n",
    "target_texts = endeDF[\"de\"].tolist()\n",
    "\n",
    "# 모델과 토크나이저 불러오기\n",
    "model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
    "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
    "\n",
    "# 데이터셋 생성\n",
    "dataset = TranslationDataset(source_texts, target_texts, tokenizer)\n",
    "\n",
    "# 파라미터 설정\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "# DataLoader 생성\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# 손실 함수 설정\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# 옵티마이저 설정\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# 모델 파인튜닝\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(dataloader, desc=f\"Epoch {epoch + 1}\"):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch[\"input_ids\"].squeeze(1)\n",
    "        attention_mask = batch[\"attention_mask\"].squeeze(1)\n",
    "        labels = batch[\"labels\"].squeeze(1)\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}, Loss: {total_loss / len(dataloader)}\")\n",
    "\n",
    "# 파인튜닝된 모델 저장\n",
    "model.save_pretrained(\"fine_tuned_model\")\n",
    "tokenizer.save_pretrained(\"fine_tuned_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TORCH_NLP38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
