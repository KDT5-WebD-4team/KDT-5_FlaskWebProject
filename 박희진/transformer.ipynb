{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c8c48a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "import torch\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import pymysql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aff84077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 테이블의 데이터수는 총 31102개 입니다.\n"
     ]
    }
   ],
   "source": [
    "# 데이터 베이스 연결하기\n",
    "conn = pymysql.connect(\n",
    "    host=\"1.251.203.204\",\n",
    "    user=\"root\",\n",
    "    password=\"kdt5\",\n",
    "    db=\"Team4\",\n",
    "    charset=\"utf8\",\n",
    "    port=33065,\n",
    ")\n",
    "\n",
    "curs = conn.cursor()\n",
    "\n",
    "# 검색 명령어 사용\n",
    "sql = \"SELECT en.text as en, de.text as de FROM language_en en join language_de de on en.id = de.id;\"\n",
    "curs.execute(sql)\n",
    "result = curs.fetchall()\n",
    "print(\"현재 테이블의 데이터수는 총 {}개 입니다.\".format(len(result)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29b11b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kdp\\AppData\\Local\\Temp\\ipykernel_1556\\3849539243.py:1: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  dataset = pd.read_sql(sql, conn)\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_sql(sql, conn)\n",
    "\n",
    "# 데이터베이스 연결 종료\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b592bc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터의 전체 개수\n",
    "total_samples = len(dataset)\n",
    "\n",
    "# 검증 데이터의 개수 (전체 데이터의 10%)\n",
    "validation_samples = int(0.1 * total_samples)\n",
    "\n",
    "# 검증 데이터셋 선택\n",
    "validation_data = dataset.iloc[:validation_samples]\n",
    "\n",
    "# 나머지 데이터를 학습 데이터셋으로 사용\n",
    "train_data = dataset.iloc[validation_samples:]\n",
    "\n",
    "# 학습 데이터셋\n",
    "train_iter = [\n",
    "    (source_text, target_text)\n",
    "    for source_text, target_text in zip(train_data[\"en\"], train_data[\"de\"])\n",
    "]\n",
    "# 검증 데이터셋\n",
    "validation_iter = [\n",
    "    (source_text, target_text)\n",
    "    for source_text, target_text in zip(validation_data[\"en\"], validation_data[\"de\"])\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5173254c-db77-4791-8f00-23a89b6cf6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "\n",
    "# 텍스트 이터레이터로부터 토큰을 생성하는 함수를 정의합니다.\n",
    "def generate_tokens(text_iter, language):\n",
    "    # 언어를 해당 언어의 인덱스에 매핑하는 사전을 생성합니다.\n",
    "    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n",
    "\n",
    "    # 텍스트 이터레이터를 반복합니다.\n",
    "    for text in text_iter:\n",
    "        # 해당 언어에 기반하여 토큰화된 텍스트를 생성합니다.\n",
    "        yield token_transform[language](text[language_index[language]])\n",
    "\n",
    "\n",
    "# 소스 및 타겟 언어를 정의합니다.\n",
    "SRC_LANGUAGE = \"en\"\n",
    "TGT_LANGUAGE = \"de\"\n",
    "\n",
    "# 특수 심볼에 대한 인덱스를 정의합니다.\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "# 특수 심볼을 정의합니다.\n",
    "special_symbols = [\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"]\n",
    "\n",
    "# 각 언어에 대한 토크나이제이션 변환을 정의합니다.\n",
    "token_transform = {\n",
    "    SRC_LANGUAGE: get_tokenizer(\"spacy\", language=\"en_core_web_sm\"),\n",
    "    TGT_LANGUAGE: get_tokenizer(\"spacy\", language=\"de_core_news_sm\"),\n",
    "}\n",
    "\n",
    "# 어휘 변환 딕셔너리를 초기화합니다.\n",
    "vocab_transform = {}\n",
    "\n",
    "# 소스 및 타겟 언어에 대해 반복합니다.\n",
    "for language in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    # 해당 언어 쌍의 훈련 데이터를 로드합니다.\n",
    "    # 토큰화된 텍스트의 이터레이터로부터 어휘를 구축합니다.\n",
    "    vocab_transform[language] = build_vocab_from_iterator(\n",
    "        generate_tokens(train_iter, language),\n",
    "        min_freq=1,\n",
    "        specials=special_symbols,\n",
    "        special_first=True,\n",
    "    )\n",
    "\n",
    "# 어휘에서 특수 토큰의 기본 인덱스를 설정합니다.\n",
    "for language in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    vocab_transform[language].set_default_index(UNK_IDX)\n",
    "\n",
    "import pickle\n",
    "\n",
    "# 소스 언어의 어휘 사전을 파일에 저장합니다.\n",
    "with open(\"en_vocab_transform.pkl\", \"wb\") as f:\n",
    "\n",
    "    pickle.dump(vocab_transform[SRC_LANGUAGE], f)\n",
    "\n",
    "# 타겟 언어의 어휘 사전을 파일에 저장합니다.\n",
    "with open(\"de_vocab_transform.pkl\", \"wb\") as f:\n",
    "    pickle.dump(vocab_transform[TGT_LANGUAGE], f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fe75c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # 포지션 정보 계산\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model)\n",
    "        )\n",
    "\n",
    "        # 사인(sin)과 코사인(cos) 함수를 사용하여 포지션 인코딩 값 계산\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 입력 텐서와 포지셔널 인코딩 값을 더한 후 드롭아웃 적용\n",
    "        x = x + self.pe[: x.size(0)]\n",
    "        return self.dropout(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8948567",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size):\n",
    "        super().__init__()\n",
    "        # 임베딩 레이어 정의\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens):\n",
    "        # 입력 토큰에 대한 임베딩 값 반환\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ec41ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_encoder_layers,  # 인코더의 레이어 수\n",
    "        num_decoder_layers,  # 디코더의 레이어 수\n",
    "        emb_size,  # 임베딩 차원의 크기\n",
    "        max_len,  # 입력 시퀀스의 최대 길이\n",
    "        nhead,  # 멀티 헤드 어텐션의 헤드 수\n",
    "        src_vocab_size,  # 소스 언어의 어휘 크기\n",
    "        tgt_vocab_size,  # 타겟 언어의 어휘 크기\n",
    "        dim_feedforward,  # 피드포워드 신경망의 은닉층 크기\n",
    "        dropout=0.1,  # 드롭아웃 비율 (기본값은 0.1)\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # 소스와 타겟 토큰 임베딩 레이어 초기화\n",
    "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
    "        # 포지셔널 인코딩 레이어 초기화\n",
    "        self.positional_encoding = PositionalEncoding(\n",
    "            d_model=emb_size, max_len=max_len, dropout=dropout\n",
    "        )\n",
    "        # 트랜스포머 모델 초기화\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=emb_size,\n",
    "            nhead=nhead,\n",
    "            num_encoder_layers=num_encoder_layers,\n",
    "            num_decoder_layers=num_decoder_layers,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        # 출력 레이어 초기화\n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        src,\n",
    "        trg,\n",
    "        src_mask,\n",
    "        tgt_mask,\n",
    "        src_padding_mask,\n",
    "        tgt_padding_mask,\n",
    "        memory_key_padding_mask,\n",
    "    ):\n",
    "        # 소스와 타겟 시퀀스에 포지셔널 인코딩 적용\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "        # 트랜스포머 모델에 입력 및 마스크 전달하여 출력 계산\n",
    "        outs = self.transformer(\n",
    "            src=src_emb,\n",
    "            tgt=tgt_emb,\n",
    "            src_mask=src_mask,\n",
    "            tgt_mask=tgt_mask,\n",
    "            memory_mask=None,\n",
    "            src_key_padding_mask=src_padding_mask,\n",
    "            tgt_key_padding_mask=tgt_padding_mask,\n",
    "            memory_key_padding_mask=memory_key_padding_mask,\n",
    "        )\n",
    "        # 출력을 선형 레이어에 통과시켜 최종 출력 계산\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src, src_mask):\n",
    "        # 인코더를 통해 소스 시퀀스를 인코딩\n",
    "        return self.transformer.encoder(\n",
    "            self.positional_encoding(self.src_tok_emb(src)), src_mask\n",
    "        )\n",
    "\n",
    "    def decode(self, tgt, memory, tgt_mask):\n",
    "        # 디코더를 통해 타겟 시퀀스를 디코딩\n",
    "        return self.transformer.decoder(\n",
    "            self.positional_encoding(self.tgt_tok_emb(tgt)), memory, tgt_mask\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd11e22d-1136-4d5a-96a8-281aaabe83bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model)\n",
    "        )\n",
    "\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[: x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
    "\n",
    "\n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_encoder_layers,\n",
    "        num_decoder_layers,\n",
    "        emb_size,\n",
    "        max_len,\n",
    "        nhead,\n",
    "        src_vocab_size,\n",
    "        tgt_vocab_size,\n",
    "        dim_feedforward,\n",
    "        dropout=0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
    "        self.positional_encoding = PositionalEncoding(\n",
    "            d_model=emb_size, max_len=max_len, dropout=dropout\n",
    "        )\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=emb_size,\n",
    "            nhead=nhead,\n",
    "            num_encoder_layers=num_encoder_layers,\n",
    "            num_decoder_layers=num_decoder_layers,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        src,\n",
    "        trg,\n",
    "        src_mask,\n",
    "        tgt_mask,\n",
    "        src_padding_mask,\n",
    "        tgt_padding_mask,\n",
    "        memory_key_padding_mask,\n",
    "    ):\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "        outs = self.transformer(\n",
    "            src=src_emb,\n",
    "            tgt=tgt_emb,\n",
    "            src_mask=src_mask,\n",
    "            tgt_mask=tgt_mask,\n",
    "            memory_mask=None,\n",
    "            src_key_padding_mask=src_padding_mask,\n",
    "            tgt_key_padding_mask=tgt_padding_mask,\n",
    "            memory_key_padding_mask=memory_key_padding_mask,\n",
    "        )\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src, src_mask):\n",
    "        return self.transformer.encoder(\n",
    "            self.positional_encoding(self.src_tok_emb(src)), src_mask\n",
    "        )\n",
    "\n",
    "    def decode(self, tgt, memory, tgt_mask):\n",
    "        return self.transformer.decoder(\n",
    "            self.positional_encoding(self.tgt_tok_emb(tgt)), memory, tgt_mask\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d88994b6-897a-462e-b4b9-c8d585dc6dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\TORCH_NLP38\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "c:\\ProgramData\\anaconda3\\envs\\TORCH_NLP38\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = Seq2SeqTransformer(\n",
    "    num_encoder_layers=3,\n",
    "    num_decoder_layers=3,\n",
    "    emb_size=512,\n",
    "    max_len=512,\n",
    "    nhead=8,\n",
    "    src_vocab_size=len(vocab_transform[SRC_LANGUAGE]),\n",
    "    tgt_vocab_size=len(vocab_transform[TGT_LANGUAGE]),\n",
    "    dim_feedforward=512,\n",
    ").to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX).to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", patience=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d92b11a3-89a0-4887-b233-4ef934ef1252",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "# 여러 전처리 함수를 연달아 적용하는 함수를 생성합니다.\n",
    "def sequential_transforms(*transforms):\n",
    "    def func(txt_input):\n",
    "        for transform in transforms:\n",
    "            txt_input = transform(txt_input)\n",
    "        return txt_input\n",
    "\n",
    "    return func\n",
    "\n",
    "\n",
    "# 입력 시퀀스에 대한 전처리 함수를 정의합니다.\n",
    "def input_transform(token_ids):\n",
    "    # 시작 토큰(BOS)과 끝 토큰(EOS)을 추가한 후 텐서를 합칩니다.\n",
    "    return torch.cat(\n",
    "        (torch.tensor([BOS_IDX]), torch.tensor(token_ids), torch.tensor([EOS_IDX]))\n",
    "    )\n",
    "\n",
    "\n",
    "# 배치 데이터를 처리하는 함수를 정의합니다.\n",
    "def collator(batch):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for src_sample, tgt_sample in batch:\n",
    "        # 소스와 타겟 샘플에 대해 텍스트 전처리를 수행합니다.\n",
    "        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n",
    "        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
    "\n",
    "    # 패딩을 적용하여 모든 시퀀스의 길이를 맞춥니다.\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
    "    return src_batch, tgt_batch\n",
    "\n",
    "\n",
    "# 언어별 텍스트 전처리 파이프라인을 설정합니다.\n",
    "text_transform = {}\n",
    "for language in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    # 토큰화, 어휘 사전, 입력 전처리를 순차적으로 적용합니다.\n",
    "    text_transform[language] = sequential_transforms(\n",
    "        token_transform[language], vocab_transform[language], input_transform\n",
    "    )\n",
    "\n",
    "# 검증 데이터를 로드하고 배치 데이터로 변환합니다.\n",
    "\n",
    "dataloader = DataLoader(validation_iter, batch_size=BATCH_SIZE, collate_fn=collator)\n",
    "# 다음 배치 데이터를 가져옵니다.\n",
    "source_tensor, target_tensor = next(iter(dataloader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25d4f176-b171-4862-9fc7-93eaea1207d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(s):\n",
    "    mask = (torch.triu(torch.ones((s, s), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    mask = (\n",
    "        mask.float()\n",
    "        .masked_fill(mask == 0, float(\"-inf\"))\n",
    "        .masked_fill(mask == 1, float(0.0))\n",
    "    )\n",
    "    return mask\n",
    "\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len), device=DEVICE).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask\n",
    "\n",
    "\n",
    "target_input = target_tensor[:-1, :]\n",
    "target_out = target_tensor[1:, :]\n",
    "\n",
    "source_mask, target_mask, source_padding_mask, target_padding_mask = create_mask(\n",
    "    source_tensor, target_input\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db94b9ae-333e-444b-9309-f9137f9afb0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\TORCH_NLP38\\lib\\site-packages\\torch\\nn\\functional.py:5109: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 48\u001b[0m\n\u001b[0;32m     46\u001b[0m train_, val_ \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m):\n\u001b[1;32m---> 48\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m     train_\u001b[38;5;241m.\u001b[39mappend(train_loss)\n\u001b[0;32m     50\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m run(model, optimizer, criterion, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[14], line 38\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(model, optimizer, criterion, split)\u001b[0m\n\u001b[0;32m     34\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(\n\u001b[0;32m     35\u001b[0m     logits\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, logits\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]), target_output\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     36\u001b[0m )\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m split \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 38\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     40\u001b[0m losses \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\TORCH_NLP38\\lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\TORCH_NLP38\\lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def run(model, optimizer, criterion, split):\n",
    "    if split == \"train\":\n",
    "        model.train()\n",
    "        dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, collate_fn=collator)\n",
    "    else:\n",
    "        model.eval()\n",
    "        dataloader = DataLoader(\n",
    "            validation_iter, batch_size=BATCH_SIZE, collate_fn=collator\n",
    "        )\n",
    "\n",
    "    losses = 0\n",
    "    for source_batch, target_batch in dataloader:\n",
    "        source_batch = source_batch.to(DEVICE)\n",
    "        target_batch = target_batch.to(DEVICE)\n",
    "\n",
    "        target_input = target_batch[:-1, :]\n",
    "        target_output = target_batch[1:, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(\n",
    "            source_batch, target_input\n",
    "        )\n",
    "\n",
    "        logits = model(\n",
    "            src=source_batch,\n",
    "            trg=target_input,\n",
    "            src_mask=src_mask,\n",
    "            tgt_mask=tgt_mask,\n",
    "            src_padding_mask=src_padding_mask,\n",
    "            tgt_padding_mask=tgt_padding_mask,\n",
    "            memory_key_padding_mask=src_padding_mask,\n",
    "        )\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(\n",
    "            logits.reshape(-1, logits.shape[-1]), target_output.reshape(-1)\n",
    "        )\n",
    "        if split == \"train\":\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        losses += loss.item()\n",
    "    ##################### 희진이 돌리는 중 ##################\n",
    "    return losses / len(list(dataloader))\n",
    "\n",
    "\n",
    "min_loss = 10\n",
    "train_, val_ = [], []\n",
    "for epoch in range(1000):\n",
    "    train_loss = run(model, optimizer, criterion, \"train\")\n",
    "    train_.append(train_loss)\n",
    "    val_loss = run(model, optimizer, criterion, \"valid\")\n",
    "    scheduler.step(val_loss)\n",
    "    val_.append(val_loss)\n",
    "    print(f\"Epoch: {epoch+1}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}\")\n",
    "    if val_loss < min_loss:\n",
    "        min_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"en2de2.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44070455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))  # 희진이 돌리는 중 -----\n",
    "plt.plot(train_, label=\"Train Loss\", c=\"red\")\n",
    "plt.plot(val_, label=\"Valid Loss\", c=\"orange\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\n",
    "    \"Loss\",\n",
    ")\n",
    "plt.title(\"Train / Vaild Loss\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4f0c96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(model, source_sentence):\n",
    "    model.eval()\n",
    "    src_tensor = torch.LongTensor([[vocab_transform[SRC_LANGUAGE](source_sentence)]])\n",
    "    src_mask = model.transformer.generate_square_subsequent_mask(src_tensor.size(1)).to(DEVICE)\n",
    "    tgt_tensor = torch.LongTensor([[BOS_IDX]]).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        output = greedy_decode(model, src_tensor, src_mask, max_len=MAX_LENGTH, start_symbol=TGT_PAD_IDX)\n",
    "    output = output[1:].flatten()\n",
    "    translation = vocab_transform[TGT_LANGUAGE].lookup_tokens(list(output.cpu().numpy()))\n",
    "    return \" \".join(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfb49846-9505-4327-b42a-0cc4d72a0a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", , , , , , , , , , , , , ,\n",
      ", , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , ,\n"
     ]
    }
   ],
   "source": [
    "def greedy_decode(model, source_tensor, source_mask, max_len, start_symbol):\n",
    "    source_tensor = source_tensor.to(DEVICE)\n",
    "    source_mask = source_mask.to(DEVICE)\n",
    "\n",
    "    memory = model.encode(source_tensor, source_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    for i in range(max_len - 1):\n",
    "        memory = memory.to(DEVICE)\n",
    "        target_mask = generate_square_subsequent_mask(ys.size(0))\n",
    "        target_mask = target_mask.type(torch.bool).to(DEVICE)\n",
    "\n",
    "        out = model.decode(ys, memory, target_mask)\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.item()\n",
    "\n",
    "        ys = torch.cat(\n",
    "            [ys, torch.ones(1, 1).type_as(source_tensor.data).fill_(next_word)], dim=0\n",
    "        )\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return ys\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Seq2SeqTransformer(\n",
    "    num_encoder_layers=3,\n",
    "    num_decoder_layers=3,\n",
    "    emb_size=512,\n",
    "    max_len=512,\n",
    "    nhead=8,\n",
    "    src_vocab_size=len(vocab_transform[SRC_LANGUAGE]),\n",
    "    tgt_vocab_size=len(vocab_transform[TGT_LANGUAGE]),\n",
    "    dim_feedforward=512,\n",
    ").to(DEVICE)\n",
    "model.load_state_dict(torch.load(\"en2de.pt\", map_location=DEVICE))\n",
    "def translate(model, source_sentence):\n",
    "    model.eval()\n",
    "    source_tensor = text_transform[SRC_LANGUAGE](source_sentence).view(-1, 1)\n",
    "    num_tokens = source_tensor.shape[0]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    tgt_tokens = greedy_decode(\n",
    "        model, source_tensor, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX\n",
    "    ).flatten()\n",
    "    output = vocab_transform[TGT_LANGUAGE].lookup_tokens(\n",
    "        list(tgt_tokens.cpu().numpy())\n",
    "    )[1:-1]\n",
    "    return \" \".join(output)\n",
    "\n",
    "\n",
    "output_oov = translate(model, \"Eine Gruppe von Menschen steht vor einem Iglu .\")\n",
    "output = translate(model, \"Und die Könige der Erde, die Vergewaltigung begangen haben und mit ihr lebhaft gelebt haben, werden über sie weinen und für sie weinen, wenn sie den Rauch ihres Brandes sehen,\")\n",
    "print(output_oov)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32d94915",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\TORCH_NLP38\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\TORCH_NLP38\\lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\TORCH_NLP38\\lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 63\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data_sample \u001b[38;5;129;01min\u001b[39;00m data_iter:\n\u001b[0;32m     61\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m token_transform[language](data_sample[language_index[language]])\n\u001b[1;32m---> 63\u001b[0m train_iter \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     64\u001b[0m     (train_data[i][\u001b[38;5;241m0\u001b[39m], train_data[i][\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(train_data))\n\u001b[0;32m     65\u001b[0m ]\n\u001b[0;32m     67\u001b[0m vocab_transform[SRC_LANGUAGE] \u001b[38;5;241m=\u001b[39m build_vocab_from_iterator(yield_tokens(train_iter, language\u001b[38;5;241m=\u001b[39mSRC_LANGUAGE))\n\u001b[0;32m     68\u001b[0m vocab_transform[TGT_LANGUAGE] \u001b[38;5;241m=\u001b[39m build_vocab_from_iterator(yield_tokens(train_iter, language\u001b[38;5;241m=\u001b[39mTGT_LANGUAGE))\n",
      "Cell \u001b[1;32mIn[19], line 64\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data_sample \u001b[38;5;129;01min\u001b[39;00m data_iter:\n\u001b[0;32m     61\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m token_transform[language](data_sample[language_index[language]])\n\u001b[0;32m     63\u001b[0m train_iter \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m---> 64\u001b[0m     (\u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m], train_data[i][\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(train_data))\n\u001b[0;32m     65\u001b[0m ]\n\u001b[0;32m     67\u001b[0m vocab_transform[SRC_LANGUAGE] \u001b[38;5;241m=\u001b[39m build_vocab_from_iterator(yield_tokens(train_iter, language\u001b[38;5;241m=\u001b[39mSRC_LANGUAGE))\n\u001b[0;32m     68\u001b[0m vocab_transform[TGT_LANGUAGE] \u001b[38;5;241m=\u001b[39m build_vocab_from_iterator(yield_tokens(train_iter, language\u001b[38;5;241m=\u001b[39mTGT_LANGUAGE))\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\TORCH_NLP38\\lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\TORCH_NLP38\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import numpy as np\n",
    "\n",
    "# Define the model architecture\n",
    "class Seq2SeqTransformer(torch.nn.Module):\n",
    "    def __init__(self, num_encoder_layers, num_decoder_layers, emb_size, max_len, nhead,\n",
    "                 src_vocab_size, tgt_vocab_size, dim_feedforward=512):\n",
    "        super(Seq2SeqTransformer, self).__init__()\n",
    "        self.transformer = torch.nn.Transformer(\n",
    "            d_model=emb_size,\n",
    "            nhead=nhead,\n",
    "            num_encoder_layers=num_encoder_layers,\n",
    "            num_decoder_layers=num_decoder_layers,\n",
    "            dim_feedforward=dim_feedforward\n",
    "        )\n",
    "        self.generator = torch.nn.Linear(emb_size, tgt_vocab_size)\n",
    "        self.src_tok_emb = torch.nn.Embedding(src_vocab_size, emb_size)\n",
    "        self.tgt_tok_emb = torch.nn.Embedding(tgt_vocab_size, emb_size)\n",
    "        self.positional_encoding = PositionalEncoding(emb_size, max_len=max_len)\n",
    "\n",
    "    def forward(self, src, tgt, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, memory_key_padding_mask):\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(tgt))\n",
    "        memory = self.transformer.encoder(src_emb, src_mask, src_key_padding_mask=src_padding_mask)\n",
    "        outs = self.transformer.decoder(tgt_emb, memory, tgt_mask, memory_mask=None,\n",
    "                                        tgt_key_padding_mask=tgt_padding_mask,\n",
    "                                        memory_key_padding_mask=memory_key_padding_mask)\n",
    "        return self.generator(outs)\n",
    "\n",
    "\n",
    "class PositionalEncoding(torch.nn.Module):\n",
    "    def __init__(self, emb_size, dropout, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, emb_size, 2).float() * (-np.log(10000.0) / emb_size))\n",
    "        pe = torch.zeros(max_len, emb_size)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "# Define the vocabulary\n",
    "SRC_LANGUAGE = 'de'\n",
    "TGT_LANGUAGE = 'en'\n",
    "token_transform = {}\n",
    "vocab_transform = {}\n",
    "token_transform[SRC_LANGUAGE] = get_tokenizer('spacy', language='de_core_news_sm')\n",
    "token_transform[TGT_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "\n",
    "def yield_tokens(data_iter, language):\n",
    "    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n",
    "    for data_sample in data_iter:\n",
    "        yield token_transform[language](data_sample[language_index[language]])\n",
    "\n",
    "train_iter = [\n",
    "    (train_data[i][0], train_data[i][1]) for i in range(len(train_data))\n",
    "]\n",
    "\n",
    "vocab_transform[SRC_LANGUAGE] = build_vocab_from_iterator(yield_tokens(train_iter, language=SRC_LANGUAGE))\n",
    "vocab_transform[TGT_LANGUAGE] = build_vocab_from_iterator(yield_tokens(train_iter, language=TGT_LANGUAGE))\n",
    "\n",
    "# Define the translation function\n",
    "def translate(model, source_sentence):\n",
    "    model.eval()\n",
    "    src_tensor = torch.LongTensor([[vocab_transform[SRC_LANGUAGE](source_sentence)]])\n",
    "    src_mask = model.transformer.generate_square_subsequent_mask(src_tensor.size(1)).to(DEVICE)\n",
    "    tgt_tensor = torch.LongTensor([[BOS_IDX]]).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        output = greedy_decode(model, src_tensor, src_mask, max_len=MAX_LENGTH, start_symbol=TGT_PAD_IDX)\n",
    "    output = output[1:].flatten()\n",
    "    translation = vocab_transform[TGT_LANGUAGE].lookup_tokens(list(output.cpu().numpy()))\n",
    "    return \" \".join(translation)\n",
    "\n",
    "\n",
    "# Load the model\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Seq2SeqTransformer(\n",
    "    num_encoder_layers=3,\n",
    "    num_decoder_layers=3,\n",
    "    emb_size=512,\n",
    "    max_len=512,\n",
    "    nhead=8,\n",
    "    src_vocab_size=len(vocab_transform[SRC_LANGUAGE]),\n",
    "    tgt_vocab_size=len(vocab_transform[TGT_LANGUAGE]),\n",
    "    dim_feedforward=512,\n",
    ").to(DEVICE)\n",
    "model.load_state_dict(torch.load(\"en2de.pt\", map_location=DEVICE))\n",
    "\n",
    "# Perform translation\n",
    "output_oov = translate(model, \"Eine Gruppe von Menschen steht vor einem Iglu .\")\n",
    "output = translate(model, \"Und die Könige der Erde, die Vergewaltigung begangen haben und mit ihr lebhaft gelebt haben, werden über sie weinen und für sie weinen, wenn sie den Rauch ihres Brandes sehen,\")\n",
    "print(output_oov)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a0ab72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
